{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Use a foundation model to build a spam email classifier\n",
    "A foundation model serves as a fundamental building block for potentially endless applications. One application we will explore in this exercise is the development of a spam email classifier using only the prompt. By leveraging the capabilities of a foundation model, this project aims to accurately identify and filter out unwanted and potentially harmful emails, enhancing user experience and security.\n",
    "\n",
    "Steps\n",
    "Identify and gather relevant data\n",
    "Build and evaluate the spam email classifier\n",
    "Build an improved classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Identify and gather relevant data\n",
    "To train and test the spam email classifier, you will need a dataset of emails that are labeled as spam or not spam. It is important to identify and gather a suitable dataset that represents a wide range of spam and non-spam emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a spam dataset at https://huggingface.co/datasets and load it using the datasets library\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"sms_spam\", split=[\"train\"])[0]\n",
    "\n",
    "for entry in dataset.select(range(3)):\n",
    "    sms = entry[\"sms\"]\n",
    "    label = entry[\"label\"]\n",
    "    print(f\"label={label}, sms={sms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenient dictionaries to convert between labels and ids\n",
    "id2label = {0: \"NOT SPAM\", 1: \"SPAM\"}\n",
    "label2id = {\"NOT SPAM\": 0, \"SPAM\": 1}\n",
    "\n",
    "for entry in dataset.select(range(3)):\n",
    "    sms = entry[\"sms\"]\n",
    "    label_id = entry[\"label\"]\n",
    "    print(f\"label={id2label[label_id]}, sms={sms}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Build and evaluate the spam email classifier\n",
    "Using the foundation model and the prepared dataset, you can create a spam email classifier.\n",
    "\n",
    "Let's write a prompt that will ask the model to classify 15 message as either \"spam\" or \"not spam\". For easier parsing, we can ask the LLM to respond in JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with this helper function that will help us format sms messages\n",
    "# for the LLM.\n",
    "def get_sms_messages_string(dataset, item_numbers, include_labels=False):\n",
    "    sms_messages_string = \"\"\n",
    "    for item_number, entry in zip(item_numbers, dataset.select(item_numbers)):\n",
    "        sms = entry[\"sms\"]\n",
    "        label_id = entry[\"label\"]\n",
    "\n",
    "        if include_labels:\n",
    "            sms_messages_string += (\n",
    "                f\"{item_number} (label={id2label[label_id]}) -> {sms}\\n\"\n",
    "            )\n",
    "        else:\n",
    "            sms_messages_string += f\"{item_number} -> {sms}\\n\"\n",
    "\n",
    "    return sms_messages_string\n",
    "\n",
    "\n",
    "print(get_sms_messages_string(dataset, range(3), include_labels=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a few messages and format them as a string\n",
    "sms_messages_string = get_sms_messages_string(\n",
    "    dataset, range(7, 15), include_labels=False\n",
    ")\n",
    "\n",
    "# Construct a query to send to the LLM including the sms messages.\n",
    "# Ask it to respond in JSON format.\n",
    "query = f\"\"\"\n",
    "{sms_messages_string}\n",
    "---\n",
    "Classify the messages above as SPAM or NOT SPAM. Respond in JSON format.\n",
    "Use the following format: {{\"0\": \"NOT SPAM\", \"1\": \"SPAM\"}}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = {\n",
    "    \"7\": \"SPAM\",\n",
    "    \"8\": \"SPAM\",\n",
    "    \"9\": \"SPAM\",\n",
    "    \"10\": \"NOT SPAM\",\n",
    "    \"11\": \"SPAM\",\n",
    "    \"12\": \"SPAM\",\n",
    "    \"13\": \"NOT SPAM\",\n",
    "    \"14\": \"NOT SPAM\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the accuracy of your classifier by comparing your responses to the labels in the dataset\n",
    "\n",
    "\n",
    "def get_accuracy(response, dataset, original_indices):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for entry_number, prediction in response.items():\n",
    "        if int(entry_number) not in original_indices:\n",
    "            continue\n",
    "\n",
    "        label_id = dataset[int(entry_number)][\"label\"]\n",
    "        label = id2label[label_id]\n",
    "\n",
    "        # If the prediction from the LLM matches the label in the dataset\n",
    "        # we increment the number of correct predictions.\n",
    "        # (Since LLMs do not always produce the same output, we use the\n",
    "        # lower case version of the strings for comparison)\n",
    "        if prediction.lower() == label.lower():\n",
    "            correct += 1\n",
    "\n",
    "        # increment the total number of predictions\n",
    "        total += 1\n",
    "\n",
    "    try:\n",
    "        accuracy = correct / total\n",
    "    except ZeroDivisionError:\n",
    "        print(\"No matching results found!\")\n",
    "        return\n",
    "\n",
    "    return round(accuracy, 2)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {get_accuracy(response, dataset, range(7, 15))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Build an improved classifier?\n",
    "If you provide the LLM with some examples for how to complete a task, it will sometimes improve its performance. Let's try that out here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a few labelled messages and format them as a string\n",
    "sms_messages_string_w_labels = get_sms_messages_string(\n",
    "    dataset, range(54, 60), include_labels=True\n",
    ")\n",
    "\n",
    "# Get the first 15 messages and format them as a string\n",
    "sms_messages_string_no_labels = get_sms_messages_string(dataset, range(7, 15))\n",
    "\n",
    "\n",
    "# Construct a query to send to the LLM including the labelled messages\n",
    "# as well as the unlabelled messages. Ask it to respond in JSON format\n",
    "query = f\"\"\"\n",
    "{sms_messages_string_w_labels}\n",
    "{sms_messages_string_no_labels}\n",
    "---\n",
    "Classify the messages above as SPAM or NOT SPAM. Respond in JSON format.\n",
    "Use the following format: {{\"0\": \"NOT SPAM\", \"1\": \"SPAM\"}}.\n",
    "Some examples have been labeled for you.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = {\n",
    "    \"7\": \"NOT SPAM\",\n",
    "    \"8\": \"SPAM\",\n",
    "    \"9\": \"SPAM\",\n",
    "    \"10\": \"NOT SPAM\",\n",
    "    \"11\": \"SPAM\",\n",
    "    \"12\": \"SPAM\",\n",
    "    \"13\": \"NOT SPAM\",\n",
    "    \"14\": \"NOT SPAM\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the accuracy?\n",
    "\n",
    "print(f\"Accuracy: {get_accuracy(response, dataset, range(7,15)):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the messages that were misclassified, if you have any\n",
    "\n",
    "\n",
    "def print_misclassified_messages(response, dataset):\n",
    "    for entry_number, prediction in response.items():\n",
    "        label_id = dataset[int(entry_number)][\"label\"]\n",
    "        label = id2label[label_id]\n",
    "\n",
    "        if prediction.lower() != label.lower():\n",
    "            sms = dataset[int(entry_number)][\"sms\"]\n",
    "            print(\"---\")\n",
    "            print(f\"Message: {sms}\")\n",
    "            print(f\"Label: {label}\")\n",
    "            print(f\"Prediction: {prediction}\")\n",
    "\n",
    "\n",
    "print_misclassified_messages(response, dataset)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
